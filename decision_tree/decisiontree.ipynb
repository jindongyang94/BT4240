{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Experimentation\n",
    "First, we import all relevant packages\n",
    "\n",
    "The crossvalidation's train_test_split() help us by splitting data into train & test set. This is easy way out before we do further processing:\n",
    "We should preprocess the data by partioning with the same percentage for training, cross_validation and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 561,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, confusion_matrix\n",
    "from sklearn import tree\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.legend_handler import HandlerLine2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading dataset\n",
    "\n",
    "Load Dataset and examine the initial features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 562,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Input data before feature selection\n",
    "input_data = pd.read_csv('processed_train.csv', index_col=0)\n",
    "\n",
    "#Input data after feature selection\n",
    "input_data_after_fs = pd.read_csv('processed_train_after_feature.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 563,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset Length::  2973\n",
      "Dataset Shape:  (2973, 217)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 2973 entries, 0 to 2972\n",
      "Columns: 217 entries, Id to age-range_\n",
      "dtypes: bool(1), float64(13), int64(201), object(2)\n",
      "memory usage: 4.9+ MB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>idhogar</th>\n",
       "      <th>Target</th>\n",
       "      <th>hacdor</th>\n",
       "      <th>hacapo</th>\n",
       "      <th>v14a</th>\n",
       "      <th>refrig</th>\n",
       "      <th>paredblolad</th>\n",
       "      <th>paredzocalo</th>\n",
       "      <th>paredpreb</th>\n",
       "      <th>...</th>\n",
       "      <th>escolari-min</th>\n",
       "      <th>escolari-max</th>\n",
       "      <th>escolari-sum</th>\n",
       "      <th>escolari-std</th>\n",
       "      <th>escolari-range_</th>\n",
       "      <th>age-min</th>\n",
       "      <th>age-max</th>\n",
       "      <th>age-sum</th>\n",
       "      <th>age-std</th>\n",
       "      <th>age-range_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ID_279628684</td>\n",
       "      <td>21eb7fcc1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>43</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ID_f29eb3ddd</td>\n",
       "      <td>0e5d7a658</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>67</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ID_68de51c94</td>\n",
       "      <td>2c7317ea8</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>92</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ID_ec05b1a7b</td>\n",
       "      <td>2b58d945f</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>33</td>\n",
       "      <td>4.272002</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>38</td>\n",
       "      <td>100</td>\n",
       "      <td>14.899664</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ID_1284f8aad</td>\n",
       "      <td>d6dae86b7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>23</td>\n",
       "      <td>5.123475</td>\n",
       "      <td>11</td>\n",
       "      <td>7</td>\n",
       "      <td>30</td>\n",
       "      <td>76</td>\n",
       "      <td>11.690452</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 217 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Id    idhogar  Target  hacdor  hacapo  v14a  refrig  paredblolad  \\\n",
       "0  ID_279628684  21eb7fcc1       4       0       0     1       1            1   \n",
       "1  ID_f29eb3ddd  0e5d7a658       4       0       0     1       1            0   \n",
       "2  ID_68de51c94  2c7317ea8       4       0       0     1       1            0   \n",
       "3  ID_ec05b1a7b  2b58d945f       4       0       0     1       1            1   \n",
       "4  ID_1284f8aad  d6dae86b7       4       1       0     1       1            1   \n",
       "\n",
       "   paredzocalo  paredpreb     ...      escolari-min  escolari-max  \\\n",
       "0            0          0     ...                10            10   \n",
       "1            0          0     ...                12            12   \n",
       "2            0          0     ...                11            11   \n",
       "3            0          0     ...                 2            11   \n",
       "4            0          0     ...                 0            11   \n",
       "\n",
       "   escolari-sum  escolari-std  escolari-range_  age-min  age-max  age-sum  \\\n",
       "0            10      0.000000                0       43       43       43   \n",
       "1            12      0.000000                0       67       67       67   \n",
       "2            11      0.000000                0       92       92       92   \n",
       "3            33      4.272002                9        8       38      100   \n",
       "4            23      5.123475               11        7       30       76   \n",
       "\n",
       "     age-std  age-range_  \n",
       "0   0.000000           0  \n",
       "1   0.000000           0  \n",
       "2   0.000000           0  \n",
       "3  14.899664          30  \n",
       "4  11.690452          23  \n",
       "\n",
       "[5 rows x 217 columns]"
      ]
     },
     "execution_count": 563,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"Dataset Length:: \", len(input_data))\n",
    "print (\"Dataset Shape: \", input_data.shape)\n",
    "input_data.info()\n",
    "input_data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are not doing any feature selection yet, we are gonna leave this section blank. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Split data into variables types - boolean, categorical, continuous, ID\n",
    "bool_var = list(input_data.select_dtypes(['bool']))\n",
    "cont_var = list(input_data.select_dtypes(['float64']))\n",
    "cat_var = list(input_data.select_dtypes(['int64']))\n",
    "id_var = list(input_data.select_dtypes(['object']))\n",
    "\n",
    "#Get dataset with only categorical variables\n",
    "cat_data = input_data[cat_var + bool_var]\n",
    "\n",
    "#Get Continuous Variables from Data\n",
    "cont_data = input_data[cont_var]\n",
    "\n",
    "#Input Data can be from all except id details\n",
    "final_input_data = input_data[cat_var + cont_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4\n",
       "1    4\n",
       "2    4\n",
       "3    4\n",
       "4    4\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 565,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_input_data['Target'].head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating X and Y variables. \n",
    "As shown above, target feature is at index 3 and the rest of the variables are the predictor variables. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = final_input_data.loc[:, final_input_data.columns != 'Target'].values\n",
    "Y = final_input_data['Target'].values\n",
    "Y=Y.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, \n",
    "                                                    random_state = 100 , stratify = Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Dataset after Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bool_var = list(input_data_after_fs.select_dtypes(['bool']))\n",
    "cont_var = list(input_data_after_fs.select_dtypes(['float64']))\n",
    "cat_var = list(input_data_after_fs.select_dtypes(['int64']))\n",
    "id_var = list(input_data_after_fs.select_dtypes(['object']))\n",
    "\n",
    "#Get dataset with only categorical variables\n",
    "cat_data_fs = input_data_after_fs[cat_var + bool_var]\n",
    "\n",
    "#Get Continuous Variables from Data\n",
    "cont_data_fs = input_data_after_fs[cont_var]\n",
    "\n",
    "#Input Data can be from all except id details\n",
    "final_input_data_fs = input_data_after_fs[cat_var + cont_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_fs = final_input_data_fs.loc[:, final_input_data_fs.columns != 'Target'].values\n",
    "Y_fs = final_input_data_fs['Target'].values\n",
    "Y_fs=Y_fs.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 570,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train_fs, X_test_fs, Y_train_fs, Y_test_fs = train_test_split(X_fs, Y_fs, test_size = 0.25, \n",
    "                                                    random_state = 100 , stratify = Y_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Baseline Decision Tree (Gini Index)\n",
    "\n",
    "1. clf_gini: Cleaned Raw Dataset\n",
    "2. clf_gini_fs: Cleaned Dataset after feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 571,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=100, splitter='best')"
      ]
     },
     "execution_count": 571,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_gini = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "                                     max_features=None, max_leaf_nodes=None,\n",
    "                                     min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "                                     min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                                     presort=False, random_state=100, splitter='best')\n",
    "clf_gini.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 572,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=100, splitter='best')"
      ]
     },
     "execution_count": 572,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using dataset after feature selection\n",
    "clf_gini_fs = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "                                     max_features=None, max_leaf_nodes=None,\n",
    "                                     min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "                                     min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                                     presort=False, random_state=100, splitter='best')\n",
    "clf_gini_fs.fit(X_train_fs, Y_train_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Baseline Decision Tree (Entropy)\n",
    "\n",
    "Using Information Gain is the same as using entropy as criterion\n",
    "1. clf_entropy: Cleaned Raw Dataset\n",
    "2. clf_entropy_fs: Cleaned Dataset after feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 573,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=100, splitter='best')"
      ]
     },
     "execution_count": 573,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_entropy = DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
    "                                     max_features=None, max_leaf_nodes=None,\n",
    "                                     min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "                                     min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                                     presort=False, random_state=100, splitter='best')\n",
    "clf_entropy.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 574,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            presort=False, random_state=100, splitter='best')"
      ]
     },
     "execution_count": 574,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using dataset after feature selection\n",
    "clf_entropy_fs = DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
    "                                     max_features=None, max_leaf_nodes=None,\n",
    "                                     min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "                                     min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                                     presort=False, random_state=100, splitter='best')\n",
    "clf_entropy_fs.fit(X_train_fs, Y_train_fs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metric For Dataset before Feature Selection\n",
    "1. Accuracy Score\n",
    "2. F1 Score\n",
    "3. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 575,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting using Dataset before Feature Selection\n",
    "Y_predict_entropy_initial = clf_entropy.predict(X_test)\n",
    "Y_predict_gini_initial = clf_gini.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 576,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing acc for entropy before feature selection is 0.581989\n",
      "Testing acc for gini before feature selection is 0.576613\n"
     ]
    }
   ],
   "source": [
    "# Assess predict score based on Accuracy Score for Dataset before Feature Selection\n",
    "\n",
    "print ('Testing acc for entropy before feature selection is %f' %accuracy_score(Y_predict_entropy_initial, Y_test))\n",
    "print ('Testing acc for gini before feature selection is %f' %accuracy_score(Y_predict_gini_initial, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 577,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing f1 score for entropy before feature selection is 0.581394\n",
      "Testing f1 score for gini before feature selection is 0.578491\n"
     ]
    }
   ],
   "source": [
    "# Assess predict score based on F1 Score for Dataset after Feature Selection\n",
    "\n",
    "print ('Testing f1 score for entropy before feature selection is %f' %f1_score(Y_test, Y_predict_entropy_initial, labels=[1,2,3,4], average='weighted'))\n",
    "print ('Testing f1 score for gini before feature selection is %f' %f1_score(Y_test, Y_predict_gini_initial, labels=[1,2,3,4], average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing confusion matrix for entropy before feature selection is \n",
      " [[ 14  15   5  21]\n",
      " [ 18  27  15  51]\n",
      " [  7  22  17  43]\n",
      " [ 22  49  43 375]]\n",
      "Testing confusion matrix for gini before feature selection is \n",
      " [[ 10  10   8  27]\n",
      " [ 14  32  20  45]\n",
      " [  7  24  17  41]\n",
      " [ 21  52  46 370]]\n"
     ]
    }
   ],
   "source": [
    "# Assess predict score based on Confusion Matrix for Dataset after Feature Selection\n",
    "\n",
    "print ('Testing confusion matrix for entropy before feature selection is \\n', confusion_matrix(Y_test, Y_predict_entropy_initial, labels=[1,2,3,4]))\n",
    "print ('Testing confusion matrix for gini before feature selection is \\n', confusion_matrix(Y_test, Y_predict_gini_initial, labels=[1,2,3,4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance Metric For Dataset after Feature Selection\n",
    "1. Accuracy Score\n",
    "2. F1 Score\n",
    "3. Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 579,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Predicting using Dataset after Feature Selection\n",
    "Y_predict_entropy_initial_fs = clf_entropy_fs.predict(X_test_fs)\n",
    "Y_predict_gini_initial_fs = clf_gini_fs.predict(X_test_fs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 580,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing acc for entropy after feature selection is 0.567204\n",
      "Testing acc for gini after feature selection is 0.602151\n"
     ]
    }
   ],
   "source": [
    "# Assess predict score based on Accuracy Score for Dataset after Feature Selection\n",
    "\n",
    "print ('Testing acc for entropy after feature selection is %f' %accuracy_score(Y_test_fs, Y_predict_entropy_initial_fs))\n",
    "print ('Testing acc for gini after feature selection is %f' %accuracy_score(Y_predict_gini_initial_fs, Y_test_fs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 581,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing f1 score for entropy after feature selection is 0.568924\n",
      "Testing f1 score for gini after feature selection is 0.602241\n"
     ]
    }
   ],
   "source": [
    "# Assess predict score based on F1 Score for Dataset after Feature Selection\n",
    "\n",
    "print ('Testing f1 score for entropy after feature selection is %f' %f1_score(Y_test_fs, Y_predict_entropy_initial_fs, labels=[1,2,3,4], average='weighted'))\n",
    "print ('Testing f1 score for gini after feature selection is %f' %f1_score(Y_test_fs, Y_predict_gini_initial_fs, labels=[1,2,3,4], average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 582,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing confusion matrix for entropy after feature selection is \n",
      " [[  9  18   6  22]\n",
      " [ 12  29  19  51]\n",
      " [  8  22  16  43]\n",
      " [ 24  46  51 368]]\n",
      "Testing confusion matrix for gini after feature selection is \n",
      " [[ 13  12   6  24]\n",
      " [ 12  31  21  47]\n",
      " [  7  20  24  38]\n",
      " [ 17  43  49 380]]\n"
     ]
    }
   ],
   "source": [
    "# Assess predict score based on Confusion Matrix for Dataset after Feature Selection\n",
    "\n",
    "print ('Testing confusion matrix for entropy after feature selection is \\n', confusion_matrix(Y_test_fs, Y_predict_entropy_initial_fs, labels=[1,2,3,4]))\n",
    "print ('Testing confusion matrix for gini after feature selection is \\n', confusion_matrix(Y_test_fs, Y_predict_gini_initial_fs, labels=[1,2,3,4]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial Classification Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report for Gini: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.19      0.18      0.19        55\n",
      "          2       0.27      0.29      0.28       111\n",
      "          3       0.19      0.19      0.19        89\n",
      "          4       0.77      0.76      0.76       489\n",
      "\n",
      "avg / total       0.58      0.58      0.58       744\n",
      "\n",
      "Classification report for Entropy: \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          1       0.23      0.25      0.24        55\n",
      "          2       0.24      0.24      0.24       111\n",
      "          3       0.21      0.19      0.20        89\n",
      "          4       0.77      0.77      0.77       489\n",
      "\n",
      "avg / total       0.58      0.58      0.58       744\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# look at classification report for the initial modelling.\n",
    "print (\"Classification report for Gini: \\n\", classification_report(Y_test, Y_predict_gini_initial))\n",
    "print (\"Classification report for Entropy: \\n\", classification_report(Y_test, Y_predict_entropy_initial))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Other Metrics\n",
    "Lets compute the cross-validation scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy for Gini: 0.50 (+/- 0.24)\n",
      "Accuracy for InfoGain: 0.49 (+/- 0.24)\n"
     ]
    }
   ],
   "source": [
    "scores = cross_val_score(clf_gini, X, Y, cv=5)\n",
    "print(\"Accuracy for Gini: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))\n",
    "\n",
    "scores = cross_val_score(clf_entropy, X, Y, cv=5)\n",
    "print(\"Accuracy for InfoGain: %0.2f (+/- %0.2f)\" % (scores.mean(), scores.std() * 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the cross validation stats are terrible. We should fix this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphing Parameters (Gini)\n",
    "\n",
    "We are going to plot each parameters on a graph, based on accuracy score as the performance metric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# I am doing this here cos I lazy\n",
    "X_test = X_test_fs\n",
    "Y_test = Y_test_fs\n",
    "X_train = X_train_fs\n",
    "Y_train = Y_train_fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY9L8P0Zv323+jAUsAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c888e5ccf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Max Depth Value: 3.0\n",
      "Corresponding Accuracy Value: 0.6612903225806451\n"
     ]
    }
   ],
   "source": [
    "max_depths = np.linspace(1, 32, 32, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for max_depth in max_depths:\n",
    "    dt = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=max_depth,\n",
    "                                     max_features=None, max_leaf_nodes=None,\n",
    "                                     min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "                                     min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                                     presort=False, random_state=100, splitter='best')\n",
    "    dt.fit(X_train, Y_train)\n",
    "    train_pred = dt.predict(X_train)\n",
    "    accuracy_train = accuracy_score(Y_train, train_pred)\n",
    "    # Add acc score to previous train results\n",
    "    train_results.append(accuracy_train)\n",
    "    y_pred = dt.predict(X_test)\n",
    "    accuracy_test = accuracy_score(Y_test, y_pred)\n",
    "    # Add acc score to previous test results\n",
    "    test_results.append(accuracy_test)\n",
    "\n",
    "line1, = plt.plot(max_depths, train_results,'b', label=\"Train Accuracy\")\n",
    "line2, = plt.plot(max_depths, test_results, 'r', label=\"Test Accuracy\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel(\"Accuracy score\")\n",
    "plt.xlabel(\"Tree depth\")\n",
    "plt.show()\n",
    "\n",
    "# Finding the best score and parameter to use\n",
    "\n",
    "best_accuracy_score = max(test_results)\n",
    "best_max_depth = max_depths[test_results.index(best_accuracy_score)]\n",
    "print ('Best Max Depth Value:', best_max_depth)\n",
    "print ('Corresponding Accuracy Value:', best_accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min Sample Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nY4zxsqRgjDHGy5KCMcYYr/8HKWuYtUUB65IAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c88975b128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Min Sample Split Value: 79.0\n",
      "Corresponding Accuracy Value: 0.6344086021505376\n"
     ]
    }
   ],
   "source": [
    "min_samples_splits = np.linspace(2, 100, 99, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for min_samples_split in min_samples_splits:\n",
    "    dt = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "                                     max_features=None, max_leaf_nodes=None,\n",
    "                                     min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "                                     min_samples_split=int(min_samples_split), min_weight_fraction_leaf=0.0,\n",
    "                                     presort=False, random_state=100, splitter='best')\n",
    "    dt.fit(X_train, Y_train)\n",
    "    train_pred = dt.predict(X_train)\n",
    "    accuracy_train = accuracy_score(Y_train, train_pred)\n",
    "    # Add acc score to previous train results\n",
    "    train_results.append(accuracy_train)\n",
    "    y_pred = dt.predict(X_test)\n",
    "    accuracy_test = accuracy_score(Y_test, y_pred)\n",
    "    # Add acc score to previous test results\n",
    "    test_results.append(accuracy_test)\n",
    "\n",
    "line1, = plt.plot(min_samples_splits, train_results,'b', label=\"Train Accuracy\")\n",
    "line2, = plt.plot(min_samples_splits, test_results, 'r', label=\"Test Accuracy\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel(\"Accuracy score\")\n",
    "plt.xlabel(\"min samples split\")\n",
    "plt.show()\n",
    "\n",
    "# Finding the best score and parameter to use\n",
    "\n",
    "best_accuracy_score = max(test_results)\n",
    "best_min_samples_split = min_samples_splits[test_results.index(best_accuracy_score)]\n",
    "print ('Best Min Sample Split Value:', best_min_samples_split)\n",
    "print ('Corresponding Accuracy Value:', best_accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min Samples Leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1c892212e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Min Samples Leaf Value: 50.0\n",
      "Corresponding Accuracy Value: 0.6760752688172043\n"
     ]
    }
   ],
   "source": [
    "min_samples_leafs = np.linspace(1, 80, 80, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for min_samples_leaf in min_samples_leafs:\n",
    "    dt = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "                                     max_features=None, max_leaf_nodes=None,\n",
    "                                     min_impurity_split=1e-07, min_samples_leaf=int(min_samples_leaf),\n",
    "                                     min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                                     presort=False, random_state=100, splitter='best')\n",
    "    dt.fit(X_train, Y_train)\n",
    "    train_pred = dt.predict(X_train)\n",
    "    accuracy_train = accuracy_score(Y_train, train_pred)\n",
    "    # Add acc score to previous train results\n",
    "    train_results.append(accuracy_train)\n",
    "    y_pred = dt.predict(X_test)\n",
    "    accuracy_test = accuracy_score(Y_test, y_pred)\n",
    "    # Add acc score to previous test results\n",
    "    test_results.append(accuracy_test)\n",
    "\n",
    "line1, = plt.plot(min_samples_leafs, train_results,'b', label=\"Train Accuracy\")\n",
    "line2, = plt.plot(min_samples_leafs, test_results, 'r', label=\"Test Accuracy\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel(\"Accuracy score\")\n",
    "plt.xlabel(\"min samples leaf\")\n",
    "plt.show()\n",
    "\n",
    "# Finding the best score and parameter to use\n",
    "\n",
    "best_accuracy_score = max(test_results)\n",
    "best_min_samples_leaf = min_samples_leafs[test_results.index(best_accuracy_score)]\n",
    "print ('Best Min Samples Leaf Value:', best_min_samples_leaf)\n",
    "print ('Corresponding Accuracy Value:', best_accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "max_features must be in (0, n_features]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-589-28231e5e862d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      8\u001b[0m                                      \u001b[0mmin_samples_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_weight_fraction_leaf\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m                                      presort=False, random_state=100, splitter='best')\n\u001b[1;32m---> 10\u001b[1;33m     \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m     \u001b[0mtrain_pred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[0maccuracy_train\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_pred\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Applications\\Anaconda\\envs\\bt4240\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    737\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 739\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m    740\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    741\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\Applications\\Anaconda\\envs\\bt4240\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    244\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"max_depth must be greater than zero. \"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    245\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmax_features\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 246\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"max_features must be in (0, n_features]\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    247\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_leaf_nodes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIntegral\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minteger\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    248\u001b[0m             raise ValueError(\"max_leaf_nodes must be integral number but was \"\n",
      "\u001b[1;31mValueError\u001b[0m: max_features must be in (0, n_features]"
     ]
    }
   ],
   "source": [
    "max_features = list(range(1,final_input_data.shape[1]))\n",
    "train_results = []\n",
    "test_results = []\n",
    "for max_feature in max_features:\n",
    "    dt = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "                                     max_features=max_feature, max_leaf_nodes=None,\n",
    "                                     min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "                                     min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                                     presort=False, random_state=100, splitter='best')\n",
    "    dt.fit(X_train, Y_train)\n",
    "    train_pred = dt.predict(X_train)\n",
    "    accuracy_train = accuracy_score(Y_train, train_pred)\n",
    "    # Add acc score to previous train results\n",
    "    train_results.append(accuracy_train)\n",
    "    y_pred = dt.predict(X_test)\n",
    "    accuracy_test = accuracy_score(Y_test, y_pred)\n",
    "    # Add acc score to previous test results\n",
    "    test_results.append(accuracy_test)\n",
    "\n",
    "line1, = plt.plot(max_features, train_results,'b', label=\"Train Accuracy\")\n",
    "line2, = plt.plot(max_features, test_results, 'r', label=\"Test Accuracy\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel(\"Accuracy score\")\n",
    "plt.xlabel(\"max_features\")\n",
    "plt.show()\n",
    "\n",
    "# Finding the best score and parameter to use\n",
    "\n",
    "best_accuracy_score = max(test_results)\n",
    "best_max_feature = max_features[test_results.index(best_accuracy_score)]\n",
    "print ('Best Max Feature Value:', best_max_feature)\n",
    "print ('Corresponding Accuracy Value:', best_accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graphing Parameters (Entropy)\n",
    "\n",
    "We are going to plot each parameters on a graph, based on accuracy score as the performance metric. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_depths = np.linspace(1, 32, 32, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for max_depth in max_depths:\n",
    "    dt = DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=max_depth,\n",
    "                                     max_features=None, max_leaf_nodes=None,\n",
    "                                     min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "                                     min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                                     presort=False, random_state=100, splitter='best')\n",
    "    dt.fit(X_train, Y_train)\n",
    "    train_pred = dt.predict(X_train)\n",
    "    accuracy_train = accuracy_score(Y_train, train_pred)\n",
    "    # Add acc score to previous train results\n",
    "    train_results.append(accuracy_train)\n",
    "    y_pred = dt.predict(X_test)\n",
    "    accuracy_test = accuracy_score(Y_test, y_pred)\n",
    "    # Add acc score to previous test results\n",
    "    test_results.append(accuracy_test)\n",
    "\n",
    "line1, = plt.plot(max_depths, train_results,'b', label=\"Train Accuracy\")\n",
    "line2, = plt.plot(max_depths, test_results, 'r', label=\"Test Accuracy\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel(\"Accuracy score\")\n",
    "plt.xlabel(\"Tree depth\")\n",
    "plt.show()\n",
    "\n",
    "# Finding the best score and parameter to use\n",
    "\n",
    "best_accuracy_score = max(test_results)\n",
    "best_max_depth = max_depths[test_results.index(best_accuracy_score)]\n",
    "print ('Best Max Depth Value:', best_max_depth)\n",
    "print ('Corresponding Accuracy Value:', best_accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min Sample Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_splits = np.linspace(2, 100, 99, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for min_samples_split in min_samples_splits:\n",
    "    dt = DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
    "                                     max_features=None, max_leaf_nodes=None,\n",
    "                                     min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "                                     min_samples_split=int(min_samples_split), min_weight_fraction_leaf=0.0,\n",
    "                                     presort=False, random_state=100, splitter='best')\n",
    "    dt.fit(X_train, Y_train)\n",
    "    train_pred = dt.predict(X_train)\n",
    "    accuracy_train = accuracy_score(Y_train, train_pred)\n",
    "    # Add acc score to previous train results\n",
    "    train_results.append(accuracy_train)\n",
    "    y_pred = dt.predict(X_test)\n",
    "    accuracy_test = accuracy_score(Y_test, y_pred)\n",
    "    # Add acc score to previous test results\n",
    "    test_results.append(accuracy_test)\n",
    "\n",
    "line1, = plt.plot(min_samples_splits, train_results,'b', label=\"Train Accuracy\")\n",
    "line2, = plt.plot(min_samples_splits, test_results, 'r', label=\"Test Accuracy\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel(\"Accuracy score\")\n",
    "plt.xlabel(\"min samples split\")\n",
    "plt.show()\n",
    "\n",
    "# Finding the best score and parameter to use\n",
    "\n",
    "best_accuracy_score = max(test_results)\n",
    "best_min_samples_split = min_samples_splits[test_results.index(best_accuracy_score)]\n",
    "print ('Best Min Sample Split Value:', best_min_samples_split)\n",
    "print ('Corresponding Accuracy Value:', best_accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min Samples Leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_samples_leafs = np.linspace(1, 80, 80, endpoint=True)\n",
    "train_results = []\n",
    "test_results = []\n",
    "for min_samples_leaf in min_samples_leafs:\n",
    "    dt = DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
    "                                     max_features=None, max_leaf_nodes=None,\n",
    "                                     min_impurity_split=1e-07, min_samples_leaf=int(min_samples_leaf),\n",
    "                                     min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                                     presort=False, random_state=100, splitter='best')\n",
    "    dt.fit(X_train, Y_train)\n",
    "    train_pred = dt.predict(X_train)\n",
    "    accuracy_train = accuracy_score(Y_train, train_pred)\n",
    "    # Add acc score to previous train results\n",
    "    train_results.append(accuracy_train)\n",
    "    y_pred = dt.predict(X_test)\n",
    "    accuracy_test = accuracy_score(Y_test, y_pred)\n",
    "    # Add acc score to previous test results\n",
    "    test_results.append(accuracy_test)\n",
    "\n",
    "line1, = plt.plot(min_samples_leafs, train_results,'b', label=\"Train Accuracy\")\n",
    "line2, = plt.plot(min_samples_leafs, test_results, 'r', label=\"Test Accuracy\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel(\"Accuracy score\")\n",
    "plt.xlabel(\"min samples leaf\")\n",
    "plt.show()\n",
    "\n",
    "# Finding the best score and parameter to use\n",
    "\n",
    "best_accuracy_score = max(test_results)\n",
    "best_min_samples_leaf = min_samples_leafs[test_results.index(best_accuracy_score)]\n",
    "print ('Best Min Samples Leaf Value:', best_min_samples_leaf)\n",
    "print ('Corresponding Accuracy Value:', best_accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_features = list(range(1,final_input_data.shape[1]))\n",
    "train_results = []\n",
    "test_results = []\n",
    "for max_feature in max_features:\n",
    "    dt = DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
    "                                     max_features=max_feature, max_leaf_nodes=None,\n",
    "                                     min_impurity_split=1e-07, min_samples_leaf=1,\n",
    "                                     min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                                     presort=False, random_state=100, splitter='best')\n",
    "    dt.fit(X_train, Y_train)\n",
    "    train_pred = dt.predict(X_train)\n",
    "    accuracy_train = accuracy_score(Y_train, train_pred)\n",
    "    # Add acc score to previous train results\n",
    "    train_results.append(accuracy_train)\n",
    "    y_pred = dt.predict(X_test)\n",
    "    accuracy_test = accuracy_score(Y_test, y_pred)\n",
    "    # Add acc score to previous test results\n",
    "    test_results.append(accuracy_test)\n",
    "\n",
    "line1, = plt.plot(max_features, train_results,'b', label=\"Train Accuracy\")\n",
    "line2, = plt.plot(max_features, test_results, 'r', label=\"Test Accuracy\")\n",
    "plt.legend(handler_map={line1: HandlerLine2D(numpoints=2)})\n",
    "plt.ylabel(\"Accuracy score\")\n",
    "plt.xlabel(\"max_features\")\n",
    "plt.show()\n",
    "\n",
    "# Finding the best score and parameter to use\n",
    "\n",
    "best_accuracy_score = max(test_results)\n",
    "best_max_feature = max_features[test_results.index(best_accuracy_score)]\n",
    "print ('Best Max Feature Value:', best_max_feature)\n",
    "print ('Corresponding Accuracy Value:', best_accuracy_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Final Tuning of Parameters\n",
    "Since there is no difference at the accuracy level between using information gain or gini coefficient, we should try changing the other parameters. \n",
    "Lets try to increase the max depth to see how that would change the result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_gini = DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
    "                                     max_features=None, max_leaf_nodes=None,\n",
    "                                     min_impurity_split=1e-07, min_samples_leaf=52,\n",
    "                                     min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                                     presort=False, random_state=100, splitter='best')\n",
    "clf_gini.fit(X_train, Y_train)\n",
    "\n",
    "clf_entropy = DecisionTreeClassifier(class_weight=None, criterion='entropy', max_depth=None,\n",
    "                                     max_features=None, max_leaf_nodes=None,\n",
    "                                     min_impurity_split=1e-07, min_samples_leaf=52,\n",
    "                                     min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
    "                                     presort=False, random_state=100, splitter='best')\n",
    "clf_entropy.fit(X_train, Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict( ) will do the model prediction, predict y based on the input x\n",
    "Y_predict_gini = clf_gini.predict(X_test)\n",
    "print ('testing acc for gini is %f' %accuracy_score(Y_predict_gini, Y_test))\n",
    "Y_predict_entropy = clf_entropy.predict(X_test)\n",
    "print ('testing acc for entropy is %f' %accuracy_score(Y_predict_entropy, Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict( ) will do the model prediction, predict y based on the input x\n",
    "print ('testing f1 score for Gini after feature selection is %f' %f1_score(Y_test_fs, Y_predict_gini, labels=[1,2,3,4], average='weighted'))\n",
    "print ('testing f1 score for Entropy after feature selection is %f' %f1_score(Y_test_fs, Y_predict_entropy, labels=[1,2,3,4], average='weighted'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# look at classification report for the above tuning.\n",
    "print (\"Classification report for Gini: \\n\", classification_report(Y_test, Y_predict_gini))\n",
    "print (\"Classification report for Entropy: \\n\", classification_report(Y_test, Y_predict_entropy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
