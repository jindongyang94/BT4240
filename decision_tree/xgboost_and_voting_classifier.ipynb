{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "The hype. So I wanna join in and try the hype\n",
    "\n",
    "## VotingClassifier (Soft and Hard)\n",
    "It is the ultimate classifier for classical machine learning methods so why not try"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, f1_score, confusion_matrix\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data before feature selection\n",
    "input_data_before_fs = pd.read_csv('processed_train.csv', index_col=0)\n",
    "\n",
    "# Input data after feature selection\n",
    "input_data_after_fs = pd.read_csv('processed_train_after_feature.csv', index_col=0)\n",
    "\n",
    "# Upsampling without feature selection\n",
    "\n",
    "# Upsampling with feature selection\n",
    "\n",
    "# Downsampling without feature selection\n",
    "\n",
    "# Upsampling with feature selection\n",
    "\n",
    "\n",
    "# List of all the input data\n",
    "input_all = {\n",
    "    \"normal_before_fs\" : input_data_before_fs,\n",
    "#     \"normal_after_fs\" : input_data_after_fs\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Functions\n",
    "from sklearn.metrics import make_scorer, roc_auc_score\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "def multiclass_roc_auc_score(y_test, y_pred, average=\"macro\"):\n",
    "    lb = LabelBinarizer()\n",
    "    lb.fit(y_test)\n",
    "    y_test = lb.transform(y_test)\n",
    "    y_pred = lb.transform(y_pred)\n",
    "    return roc_auc_score(y_test, y_pred, average=average)\n",
    "\n",
    "def metric_consolidation(input_all, classifier, method = \"cross_validation\"):\n",
    "    metrics = {'accuracy': 'accuracy',\n",
    "               'f1_weighted': 'f1_weighted',\n",
    "               'roc_auc': make_scorer(multiclass_roc_auc_score, average='weighted')\n",
    "              }\n",
    "    \n",
    "    for input_name, input_data in input_all.items():\n",
    "        # split the data\n",
    "        x_train, x_test, y_train, y_test = preprocessing(input_data)\n",
    "\n",
    "        # fit the classifier to the training data\n",
    "        classifier.fit(x_train, y_train)\n",
    "\n",
    "        # apply all metrics to the classifier for cross_validation\n",
    "        if method == \"cross_validation\":\n",
    "            scores = tenfold(classifier, x_train, y_train, metric = metrics)\n",
    "            print (\"Metrics for %s: \\n\" %input_name)\n",
    "            for metric in metrics:\n",
    "                test_score_name = \"test_\" + metric\n",
    "                test_score = scores[test_score_name]\n",
    "                print (\"%s Test Score: %f +/- %f\" %(metric, test_score.mean(),\n",
    "                                               test_score.std()))   \n",
    "            print (\"\\n\")\n",
    "            \n",
    "def preprocessing(data):\n",
    "    #Split data into variables types - boolean, categorical, continuous, ID\n",
    "    bool_var = list(data.select_dtypes(['bool']))\n",
    "    cont_var = list(data.select_dtypes(['float64']))\n",
    "    cat_var = list(data.select_dtypes(['int64']))\n",
    "\n",
    "    #Input Data can be from all except id details\n",
    "    final_input_data = data[cat_var + cont_var + bool_var]\n",
    "    \n",
    "    x = final_input_data.loc[:, final_input_data.columns != 'Target'].values\n",
    "    y = final_input_data['Target'].values\n",
    "    y=y.astype('int')\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.25, \n",
    "                                                    random_state = 100 , stratify = y)\n",
    "    \n",
    "    return x_train, x_test, y_train, y_test\n",
    "\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "def tenfold(model, x, y, metric='accuracy'):\n",
    "    kfold = StratifiedKFold(n_splits=10, random_state=100, shuffle=True)\n",
    "    scores = cross_validate(model, x, y, cv=kfold, scoring=metric, \n",
    "                            return_train_score=True)\n",
    "    return scores\n",
    "\n",
    "# accuracy_mean = scores['test_score'].mean()\n",
    "# accuracy_std = scores['train_score'].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Classifier\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "\n",
    "clf1 = LogisticRegression(solver='lbfgs', multi_class='multinomial',\n",
    "                          random_state=1)\n",
    "clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "\n",
    "\n",
    "eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], \n",
    "                        voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Voting Classifier Parameters\n",
    "\n",
    "voting_values = ['hard', 'soft']\n",
    "\n",
    "for voting in voting_values:\n",
    "    clf1 = LogisticRegression(solver='lbfgs', multi_class='multinomial',\n",
    "                          random_state=1)\n",
    "    clf2 = RandomForestClassifier(n_estimators=50, random_state=1)\n",
    "\n",
    "    eclf = VotingClassifier(estimators=[('lr', clf1), ('rf', clf2), ('gnb', clf3)], \n",
    "                        voting='hard')\n",
    "    \n",
    "    print (\"For Voting Classifier with: \\n voting: %s \\n\" %(voting))\n",
    "    metric_consolidation(input_all, eclf)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
